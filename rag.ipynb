{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c49cd517-416a-47cf-bf15-b5d81228ec0c",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d81bc7-9aec-4b06-b31e-da9773c4c9c4",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "### Make a `.env` file\n",
    "\n",
    "```sh\n",
    "cp .env.example .env\n",
    "```\n",
    "\n",
    "### Provide API keys in `.env` file \n",
    "\n",
    "- LANGCHAIN_API_KEY (optional)\n",
    "  -  Sign up to https://smith.langchain.com/\n",
    "  -  Go to Settings -> API Keys\n",
    "  -  Create API Key\n",
    "- GROQ_API_KEY\n",
    "  - Sign up to https://console.groq.com/\n",
    "  - Go to API Keys\n",
    "  - Create API Key\n",
    "\n",
    "### Check that everything is working\n",
    "\n",
    "- Check that the configured Kernel is `.venv`\n",
    "  - In the navigation bar, click `Kernel`\n",
    "  - Click `Change Kernel...`\n",
    "- Check that all cells are working\n",
    "  - In the navigation bar, click `Kernel`\n",
    "  - Click `Restart Kernel...`\n",
    "  - In the navigation bar, click `Edit`\n",
    "  - Click `Clear Outputs of All Cells`\n",
    "  - In the navigation bar, click `Run`\n",
    "  - Click `Run All Cells`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c8f9cc-50c7-4838-a3a9-ec79ee0e0480",
   "metadata": {},
   "source": [
    "## Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7acb2bd-728f-4deb-89f0-6a00d4478fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46657b90-4a35-4443-a67c-a9cd3e697a13",
   "metadata": {},
   "source": [
    "## Set up tracing\n",
    "Define `LANGCHAIN_API_KEY` in your `.env` file.  \n",
    "This step is optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "457a528f-5971-44b8-aa72-c594ca80b7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aab1ae7-b891-4a6d-aa33-a499a76a5c99",
   "metadata": {},
   "source": [
    "## Set up LLM\n",
    "Define `GROQ_API_KEY` in your `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c35c49d-248f-43c7-82d6-d18dfc7d9f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model=\"llama3-8b-8192\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f30fd11-ddb6-41ee-aa15-1c540ab62b90",
   "metadata": {},
   "source": [
    "## Indexing: Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "682d9746-8b51-4ad0-899e-94a56eea824e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43131"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# Only keep post title, headers, and content from the full HTML.\n",
    "bs4_strainer = bs4.SoupStrainer(class_=(\"post-title\", \"post-header\", \"post-content\"))\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs={\"parse_only\": bs4_strainer},\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "len(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64c2a33-fe18-4846-86b0-0c12e66182c7",
   "metadata": {},
   "source": [
    "## Indexing: Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ec74fe9-3ab5-4e75-9e17-93ba3dd19eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    add_start_index=True,\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "len(all_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e35c5ca-8e11-4e12-be9c-cfdbb6731999",
   "metadata": {},
   "source": [
    "## Indexing: Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82953a89-8ade-4141-9ce5-d636e396aa33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing started...\n",
      "Indexing complete.\n"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "print(\"Indexing started...\")\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=HuggingFaceEmbeddings())\n",
    "print(\"Indexing complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ca037b-3c19-401f-828e-f7b402875a61",
   "metadata": {},
   "source": [
    "## Retrieval and Generation: Retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1e5dedc-1a55-45ec-a9a6-804e7d7919dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n",
    "retrieved_docs = retriever.invoke(\"What are the approaches to Task Decomposition?\")\n",
    "\n",
    "len(retrieved_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93cbef8-f8ef-4336-b90f-42774d53aacc",
   "metadata": {},
   "source": [
    "## Retrieval and Generation: Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b42ec55a-613b-4b68-85ae-eda35a43d128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: filler question \\nContext: filler context \\nAnswer:\")]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "example_messages = prompt.invoke({\n",
    "    \"context\": \"filler context\",\n",
    "    \"question\": \"filler question\",\n",
    "}).to_messages()\n",
    "\n",
    "example_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "644569f0-f7a7-4c66-af4d-42a223546b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task decomposition is a process that breaks down a problem or task into smaller, more manageable subtasks or steps."
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "for chunk in rag_chain.stream(\"What is Task Decomposition?\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
